{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 264,
      "metadata": {
        "id": "sbpngF0a5twG"
      },
      "outputs": [],
      "source": [
        "# @title Autor: Alan Echer\n",
        "# O algoritmo abaixo foi criado baseado nas funcoes apreendidas na aula de\n",
        "# IA e machine learning do INFNET\n",
        "\n",
        "# passos para fazer ao analisar os dados\n",
        "#adicionar dependencias\n",
        "#carregar os dados dos dataset\n",
        "#analisar de dados\n",
        "#normalizar dados das colunas\n",
        "#verificar dados nullos\n",
        "#verificar dados categoricos\n",
        "#verificar representatividade dos dados do objetivo em relação ao restante dos dados\n",
        "#(objetivo = 1, restante = 0)\n",
        "#normalizar os dados\n",
        "#verificar separabilidade linear\n",
        "#separar os dados treino / teste estratificando\n",
        "#definir o baseline otimista / pessimista\n",
        "#gerar os dados estatisticos\n",
        "#otimizacao verificar os falsos positivos e falsos negativos em funcao do limiar minimo\n",
        "#otimizacao verificar o precisao e recall em funcao do limiar minimo\n",
        "#otimizacao verificar curva ROC vs classificador aleatorio\n",
        "#otimizacao lucro medio em relacao ao limiar minimo\n",
        "#gerar o modelo e os dados estatisticos\n",
        "#comparar com os modelos otimista e pessimistas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import matplotlib.colors as colors\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "9VFnVKeC52ys"
      },
      "execution_count": 265,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# o codigo abaixo sao todas as funcoes utilizadas pelo algoritmo para tratar e analisar os dados, nao devem ser alteradas\n",
        "\n",
        "def loadAnaliseAndTransformData(cache, configuration, y_column):\n",
        "  data = loadDataSetFromGDriveOrCache(cache, configuration)\n",
        "\n",
        "  reAddDroppedColumnsBefore(configuration, cache, data)\n",
        "\n",
        "  if(configuration['normalize_columns']['enabled']):\n",
        "    print()\n",
        "    print('=> Normalizing column names...')\n",
        "    normalizeColumnNames(configuration, data)\n",
        "    print('=> Normalizing column names... OK')\n",
        "\n",
        "  transformData(configuration, cache, data)\n",
        "\n",
        "  if(configuration['drop_columns']['enabled']):\n",
        "    print()\n",
        "    print('=> Dropping columns...')\n",
        "    dropColumns(configuration, cache, data)\n",
        "    print('=> Dropping columns... OK')\n",
        "\n",
        "  if(configuration['confusion_matrix']['enabled']):\n",
        "    print()\n",
        "    print('=> Generating confusion matrix...')\n",
        "    generateConfusionMatrix(y_column, data)\n",
        "    print('=> Generating confusion matrix... OK')\n",
        "\n",
        "  if(configuration['pair_plot']['enabled']):\n",
        "    print()\n",
        "    print('=> Plotting pair plot...')\n",
        "    plotPairPlot(configuration, data)\n",
        "    print('=> Plotting pair plot... OK')\n",
        "\n",
        "  if(configuration['dataset']['show_data']['enabled']):\n",
        "    showDataInfo(configuration, data)\n",
        "\n",
        "  return data\n",
        "\n",
        "def loadDataSetFromGDriveOrCache(cache, configuration):\n",
        "  if(cache['dataset'] is None):\n",
        "    if(configuration['dataset']['source_provider'] == 'gdrive'):\n",
        "      print('=> Mounting google drive...')\n",
        "      drive.mount('/content/drive')\n",
        "      print('=> Mounting google drive... OK')\n",
        "    else:\n",
        "      print('=> ERROR: Source provider not supported: '+configuration['dataset']['source_provider'])\n",
        "      return\n",
        "\n",
        "    if(configuration['dataset']['reader_type'] == 'csv'):\n",
        "      print()\n",
        "      print('=> Reading csv data...')\n",
        "      cache['dataset'] = pd.read_csv('/content/drive/MyDrive/'+configuration['dataset']['path'], sep=configuration['dataset']['sep'])\n",
        "      print('=> Reading csv data... OK')\n",
        "      return cache['dataset']\n",
        "    else:\n",
        "      print('=> ERROR: Reader type not supported: '+configuration['dataset']['reader_type'])\n",
        "      return\n",
        "  else:\n",
        "    print()\n",
        "    print('=> Using cached dataset... OK')\n",
        "  return cache['dataset']\n",
        "\n",
        "def showDataInfo(configuration, data):\n",
        "  if(configuration['dataset']['show_data']['dataset_head']):\n",
        "    print()\n",
        "    print('=> Dataset head: ')\n",
        "    print(data.head())\n",
        "\n",
        "  if(configuration['dataset']['show_data']['dataset_info']):\n",
        "    print()\n",
        "    print('=> Dataset info: ')\n",
        "    print(data.info())\n",
        "\n",
        "  if(configuration['dataset']['show_data']['dataset_describe']):\n",
        "    print()\n",
        "    print('=> Dataset describe: ')\n",
        "    print(data.describe())\n",
        "\n",
        "  if(configuration['dataset']['show_data']['dataset_nulls']):\n",
        "    print()\n",
        "    print('=> Dataset nulls: ')\n",
        "    print(data.isnull().sum())\n",
        "\n",
        "  if(configuration['dataset']['show_data']['dataset_duplicated']):\n",
        "    print()\n",
        "    print('=> Dataset duplicated: ')\n",
        "    print(data.duplicated().sum())\n",
        "\n",
        "  if(configuration['dataset']['show_data']['dataset_unique_values']):\n",
        "    print()\n",
        "    print('=> Dataset unique values: ')\n",
        "    for column in data.columns:\n",
        "      print()\n",
        "      print('=> Column: '+column, data[column].unique())\n",
        "\n",
        "  if(configuration['dataset']['show_data']['dataset_value_counts']):\n",
        "    print()\n",
        "    print('=> Dataset value counts: ')\n",
        "    for column in data.columns:\n",
        "      print()\n",
        "      print('=> Column: ', data[column].value_counts(normalize=True))\n",
        "  pass\n",
        "\n",
        "def transformData(configuration, cache, data):\n",
        "  for transformation in configuration['data_transformation']['transformations']:\n",
        "    columnName = transformation['column']\n",
        "    #backup original data column for cenarios where you need to run transformation multiple times\n",
        "    #and not want to loose original data\n",
        "    cachedColumns = cache['original_data_before_transformation']\n",
        "    if(not transformation['enabled']):\n",
        "      if(cachedColumns.get(columnName) is not None):\n",
        "        data[columnName] = cachedColumns[columnName]\n",
        "      continue\n",
        "    print()\n",
        "    print()\n",
        "    print('=> Applying data transformations...')\n",
        "    if(cachedColumns.get(columnName) is None):\n",
        "      cachedColumns[columnName] = data[columnName]\n",
        "    data[columnName] = cachedColumns[columnName].apply(transformation['function'])\n",
        "    print('=> Applying data transformations... OK')\n",
        "  pass\n",
        "\n",
        "def normalizeColumnNames(configuration, data):\n",
        "  normalize = configuration['normalize_columns']\n",
        "  if(normalize['modificator'] == 'lower'):\n",
        "    data.columns = data.columns.str.lower()\n",
        "  elif(normalize['modificator'] == 'upper'):\n",
        "    data.columns = data.columns.str.upper()\n",
        "  else:\n",
        "    print('=> ERROR: modificator unsuported!')\n",
        "  for column in data.columns:\n",
        "    for replacement in normalize['replacements']:\n",
        "      data.columns = data.columns.str.replace(replacement['char_to_replace'], replacement['replace_with'])\n",
        "  pass\n",
        "\n",
        "def reAddDroppedColumnsBefore(configuration, cache, data):\n",
        "  columns = []\n",
        "  for column in cache['original_data_before_drop']:\n",
        "    if(cache['original_data_before_drop'].get(column) is not None):\n",
        "      print()\n",
        "      print('=> Recriando coluna previamente deletada: ', column)\n",
        "      data[column] = cache['original_data_before_drop'][column]\n",
        "      columns.append(column)\n",
        "      print('=> Recriando coluna previamente deletada... OK')\n",
        "  for column in columns:\n",
        "     print()\n",
        "     print('=> Apagando coluna restaurada do cache: ', column)\n",
        "     del cache['original_data_before_drop'][column]\n",
        "     print('=> Apagando coluna restaurada do cache... OK')\n",
        "  pass\n",
        "\n",
        "def dropColumns(configuration, cache, data):\n",
        "  for column in configuration['drop_columns']['columns']:\n",
        "    cache['original_data_before_drop'][column] = data[column]\n",
        "  return data.drop(columns=configuration['drop_columns']['columns'], inplace=True)\n",
        "\n",
        "def checkColumnTypesAreNumbers(data, columns):\n",
        "  invalidColumns=[]\n",
        "  for column in columns:\n",
        "    for value in data[column].unique():\n",
        "      try:\n",
        "        float(value)\n",
        "      except ValueError:\n",
        "        print()\n",
        "        print('=> ERROR: this column cannot be used to pair plot because it not have numerical values: ', column)\n",
        "        print('=> ERROR: value: ', value)\n",
        "        invalidColumns.append(column)\n",
        "        break\n",
        "  for column in invalidColumns:\n",
        "    print()\n",
        "    print('=> Removing invalid column for pair plot: ', column)\n",
        "    columns.remove(column)\n",
        "  pass\n",
        "\n",
        "def plotPairPlot(configuration, data):\n",
        "  if(configuration['pair_plot']['type'] == '2d'):\n",
        "    hue = hue=configuration['pair_plot']['hue_column']\n",
        "    if(configuration['pair_plot']['columns'] == 'all'):\n",
        "      columns = []\n",
        "      for column in data.columns:\n",
        "        columns.append(column)\n",
        "      print()\n",
        "      print('=> Plotting pair plot with all columns: ', columns)\n",
        "      checkColumnTypesAreNumbers(data, columns)\n",
        "      sns.pairplot(data=data, hue=hue)\n",
        "    elif (configuration['pair_plot']['columns'] == 'selection'):\n",
        "      selection = configuration['pair_plot']['selection']\n",
        "      if(hue not in selection):\n",
        "        selection.append(hue)\n",
        "      checkColumnTypesAreNumbers(data, selection)\n",
        "      data_to_plot = data.loc[:,selection]\n",
        "      print()\n",
        "      print('=> Plotting pair plot with columns: ', selection)\n",
        "      sns.pairplot(data=data_to_plot, hue=hue)\n",
        "    else:\n",
        "      print('=> ERROR: Pair plot columns not supported: '+configuration['pair_plot']['columns'])\n",
        "      return\n",
        "  else:\n",
        "    print('=> ERROR: Pair plot type not supported: '+configuration['pair_plot']['type'])\n",
        "    return\n",
        "  pass\n",
        "\n",
        "def generateConfusionMatrix(y_column, data):\n",
        "  unique_values = data[y_column].unique()\n",
        "  if(len(unique_values) == 2):\n",
        "    if((unique_values[0] == 1 or unique_values[0] == 0) and (unique_values[1] == 1 or unique_values[1] == 0)):\n",
        "      y_optimist = [0] * len(data[y_column])\n",
        "      y_pessimist = [1] * len(data[y_column])\n",
        "      print()\n",
        "      print('=> Imprimindo matriz de confusão otimista (0)')\n",
        "      printConfusionMatrix(y_optimist, data)\n",
        "      print()\n",
        "      print('=> Imprimindo matriz de confusão pessimista (1)')\n",
        "      printConfusionMatrix(y_pessimist, data)\n",
        "    else:\n",
        "      print('=> ERROR: Y column has following values: ', unique_values)\n",
        "      print('=> ERROR: Y column must contain only two values: 0, 1')\n",
        "  else:\n",
        "    print('=> ERROR: Y column has following values: ', unique_values)\n",
        "    print('=> ERROR: Y column must contain only two values: 0, 1')\n",
        "  pass\n",
        "\n",
        "def printConfusionMatrix(y_optimist, data):\n",
        "  print()\n",
        "  cm = confusion_matrix(data[y_column], y_optimist)\n",
        "  labels = np.array([[\"TN[{}]\".format(cm[0,0]), \"FP[{}]\".format(cm[0,1])],\n",
        "                   [\"FN[{}]\".format(cm[1,0]), \"TP[{}]\".format(cm[1,1])]])\n",
        "  sns.heatmap(cm,  annot=labels, fmt='', cmap=\"Blues\")\n",
        "  plt.title('Matriz de Confusão - Regressão Logistica')\n",
        "  plt.xlabel('Saida do Modelo')\n",
        "  plt.ylabel('Saida Esperada')\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "  pass\n"
      ],
      "metadata": {
        "id": "J1U6IAkK58Od"
      },
      "execution_count": 266,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# as variaveis abaixo mantem o cache de alguns dados antes das transformacoes,\n",
        "# drops ou carregamento do gdrive para melhorias de performance e integridade\n",
        "# das informacoes quando sao feitas execucoes de codigo parciais no colab\n",
        "cache = {\n",
        "    'dataset':None,\n",
        "    'original_data_before_transformation':{},\n",
        "    'original_data_before_drop':{},\n",
        "}"
      ],
      "metadata": {
        "id": "FTgEBTYE57TP"
      },
      "execution_count": 267,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Esta é a configuracao inicial nela voce irá alterar as variaveis para que\n",
        "# sua analise seja feita corretamente, nao se preocupe com a quantidade de\n",
        "# informacao e nem no que será colocado em cada campo neste momento\n",
        "# pois a maioria dos trechos estao desabilitados 'enabled': False entao nao\n",
        "# serao executados.\n",
        "\n",
        "# 1. Comece pela seção dataset, informando sua fonte de dados de acordo com os\n",
        "# comentarios.\n",
        "\n",
        "# 1.2. Na seção show_data será possível exibir os dados do dataset carregado.\n",
        "\n",
        "# Somente com essas duas seções preenchidas já será possível executar o codigo\n",
        "# e verificar os dados carregados no dataset.\n",
        "\n",
        "# 2. Na seção normalize_columns será possível transformar as colunas\n",
        "# substituindo caracteres.\n",
        "\n",
        "# 3. Na seção data_transformation será possível transformar os dados das linhas\n",
        "# atraves de uma função lambda que retornará o novo dado baseado na sua logica.\n",
        "\n",
        "# 4. Na seção drop_columns será possível excluir algumas colunas do dataset.\n",
        "\n",
        "# 5. Na seção pair_plot será possível configurar a plotagem dos pares para\n",
        "# analise da separabilidade linear.\n",
        "# (Não esqueça de preencher a variavel 'y_column')\n",
        "\n",
        "# 6. Na seção confusion_matrix será possível configurar a plotagem da matrix de\n",
        "# confusão.\n",
        "# (Não esqueça de preencher a variavel 'y_column')\n",
        "\n",
        "y_column = 'drug'\n",
        "\n",
        "configuration = {\n",
        "    'show_debug_info':True, #TODO implementar nivel de log\n",
        "    'dataset':{\n",
        "        'source_provider':'gdrive',# only supported google drive\n",
        "        'reader_type':'csv',# only supported csv\n",
        "        'path':'ALGORITMOS DE IA/DATASET/winequalityN.csv',# CAMINHO PARA O SEU DATASET NO GDRIVE\n",
        "        'sep':',',# SEPARADOR DOS DADOS DO SEU DATASET, POR EX: , OU ; OU OUTRO\n",
        "        'show_data':{# SECAO PARA CONFIGURACAO DOS LOGS\n",
        "            'enabled':True,\n",
        "            'dataset_head':True,\n",
        "            'dataset_info':False,\n",
        "            'dataset_describe':False,\n",
        "            'dataset_nulls':False,\n",
        "            'dataset_duplicated':False,\n",
        "            'dataset_unique_values':False,\n",
        "            'dataset_value_counts':False,\n",
        "        },\n",
        "    },\n",
        "    'normalize_columns':{# SECAO PARA CONFIGURACAO DA NORMALIZACAO DAS COLUNAS\n",
        "        'enabled':True,\n",
        "        'modificator': 'lower',# ALLOWED ONLY 'lower' or 'upper' value\n",
        "        'replacements':[\n",
        "            {\n",
        "                'char_to_replace':' ',\n",
        "                'replace_with':'_'\n",
        "            },\n",
        "            {\n",
        "                'char_to_replace':'(',\n",
        "                'replace_with':''\n",
        "            },\n",
        "            {\n",
        "                'char_to_replace':')',\n",
        "                'replace_with':''\n",
        "            },\n",
        "        ]\n",
        "    },\n",
        "    'data_transformation':{ #SECAO PARA CONFIGURACAO DA TRANSFORMACAO DOS DADOS\n",
        "        'transformations':[\n",
        "            {\n",
        "                'enabled':False,\n",
        "                'column':'sex',\n",
        "                'function':lambda r:1 if r == 'M' else 0\n",
        "            },\n",
        "            {\n",
        "                'enabled':False,\n",
        "                'column':'drug',\n",
        "                'function':lambda r:1 if r == 'drugC' else 0\n",
        "            },\n",
        "        ]\n",
        "    },\n",
        "    'drop_columns':{\n",
        "        'enabled':False,\n",
        "        'columns':['sex', 'bp']\n",
        "    },\n",
        "    'pair_plot':{\n",
        "        'enabled':False,\n",
        "        'type':'2d', # only 2d available\n",
        "        'columns':'all', # all or selection\n",
        "        'selection':['age','sex', 'na_to_k'],# or add specific columns here, remember to add hue_column value here too\n",
        "        'hue_column':y_column,\n",
        "    },\n",
        "    'confusion_matrix':{\n",
        "        'enabled':False,\n",
        "        'generate_optimist':True,\n",
        "        'generate_pessimist':True,\n",
        "    }\n",
        "}\n",
        "\n",
        "data = loadAnaliseAndTransformData(cache, configuration, y_column)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kojFcTeQKPwf",
        "outputId": "f501d7aa-e500-49fc-e8d7-af09f6e53246"
      },
      "execution_count": 268,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Mounting google drive...\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "=> Mounting google drive... OK\n",
            "\n",
            "=> Reading csv data...\n",
            "=> Reading csv data... OK\n",
            "\n",
            "=> Normalizing column names...\n",
            "=> Normalizing column names... OK\n",
            "\n",
            "=> Dataset head: \n",
            "    type  fixed_acidity  volatile_acidity  citric_acid  residual_sugar  \\\n",
            "0  white            7.0              0.27         0.36            20.7   \n",
            "1  white            6.3              0.30         0.34             1.6   \n",
            "2  white            8.1              0.28         0.40             6.9   \n",
            "3  white            7.2              0.23         0.32             8.5   \n",
            "4  white            7.2              0.23         0.32             8.5   \n",
            "\n",
            "   chlorides  free_sulfur_dioxide  total_sulfur_dioxide  density    ph  \\\n",
            "0      0.045                 45.0                 170.0   1.0010  3.00   \n",
            "1      0.049                 14.0                 132.0   0.9940  3.30   \n",
            "2      0.050                 30.0                  97.0   0.9951  3.26   \n",
            "3      0.058                 47.0                 186.0   0.9956  3.19   \n",
            "4      0.058                 47.0                 186.0   0.9956  3.19   \n",
            "\n",
            "   sulphates  alcohol  quality  \n",
            "0       0.45      8.8        6  \n",
            "1       0.49      9.5        6  \n",
            "2       0.44     10.1        6  \n",
            "3       0.40      9.9        6  \n",
            "4       0.40      9.9        6  \n"
          ]
        }
      ]
    }
  ]
}